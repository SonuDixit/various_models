{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embedding_forward(x, W):\n",
    "  out, cache = None, None\n",
    "  N, T = x.shape\n",
    "  V, D = W.shape\n",
    "  out = W[x]\n",
    "  cache = (V, x)\n",
    "  return out, cache  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim   = 512   # CNN features dimension: 512  \n",
    "hidden_dim  = 512   # Hidden state dimension: 512\n",
    "# W_proj: (input_dim, hidden_dim)\n",
    "W_proj  = np.random.randn(input_dim, hidden_dim)\n",
    "W_proj /= np.sqrt(input_dim)\n",
    "b_proj  = np.zeros(hidden_dim)\n",
    "# Initialize CNN -> hidden state projection parameters\n",
    "# h0: (N, hidden_dim)\n",
    "h0 = features.dot(W_proj) + b_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec_dim = 256  # Convert a work index to a vector of 256 numbers.\n",
    "W_embed  = np.random.randn(vocab_size, wordvec_dim)\n",
    "W_embed /= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T = 16: Number of unroll time step.\n",
    "# captions:    (N, T+1) The caption represent \"<start> A yellow school bus idles near a park <end> <null> ... <null>\" represent in word index. \n",
    "# captions_in  (N, T) The caption feed into the RNN (X) = captions without the last word.\n",
    "# captions_out (N, T) The true caption output: the caption without \"<start>\"\n",
    "\n",
    "# W_embed (vocab_size, wordvec_dim)\n",
    "# captions_in: (N, T) each captions_in contain at most 16 words.\n",
    "# x: (N, T, wordvec_dim)\n",
    "x, cache_embed = word_embedding_forward(captions_in, W_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def loss(self, features, captions):\n",
    "    # For training, say the caption is \"<start> A yellow bus idles near a park\"\n",
    "    # captions_in is the Xt input: \"<start> A yellow bus idles near a\"\n",
    "    # captions_out is the true label: \"A yellow bus idles near a park\"\n",
    "    captions_in = captions[:, :-1]\n",
    "    captions_out = captions[:, 1:]\n",
    "    \n",
    "    mask = (captions_out != self._null)\n",
    "\n",
    "    # Retrieve the trainable parameters\n",
    "    W_proj, b_proj = self.params['W_proj'], self.params['b_proj']    \n",
    "    W_embed = self.params['W_embed']\n",
    "    Wx, Wh, b = self.params['Wx'], self.params['Wh'], self.params['b']\n",
    "    W_vocab, b_vocab = self.params['W_vocab'], self.params['b_vocab']\n",
    "    \n",
    "    loss, grads = 0.0, {}\n",
    "    # vocab_size = 1004\n",
    "    # T          = 16\n",
    "    #\n",
    "    # features    : (N, input_dim)\n",
    "    # W_proj      : (input_dim, hidden_dim)\n",
    "    # h0          : (N, hidden_dim)\n",
    "    #\n",
    "    # x           : (N, T, wordvec_dim)\n",
    "    # captions_in : (N, T) of word index\n",
    "    # W-embed     : (vacab_size, wordvec_dim)\n",
    "    #\n",
    "    # h           : (N, 16, hidden_dim)\n",
    "    # Wx          : (wordvec_dim, hidden_dim)\n",
    "    # Wh          : (hidden_dim, hidden_dim)\n",
    "    #\n",
    "    # scores      : (N, 16, vocab_size)\n",
    "    # W_vocab     : (hidden_dim, vocab_size)\n",
    "\n",
    "    # Compute h0 from the image features.\n",
    "    h0 = features.dot(W_proj) + b_proj\n",
    "\n",
    "    # Find the word vector of the input caption word.\n",
    "    x, cache_embed = word_embedding_forward(captions_in, W_embed)\n",
    "\n",
    "    # Forward feed for the RNN\n",
    "    h, cache_rnn = rnn_forward(x, h0, Wx, Wh, b)\n",
    "\n",
    "    # Compute the scores for each words in the vocabulary\n",
    "    scores, cache_scores = temporal_affine_forward(h, W_vocab, b_vocab)\n",
    "    # Compute the softmax loss\n",
    "    loss, dscores = temporal_softmax_loss(scores, captions_out, mask)\n",
    "\n",
    "    # Perform the backpropagation\n",
    "    dh, grads['W_vocab'], grads['b_vocab'] = temporal_affine_backward(dscores, cache_scores)\n",
    "    dx, dh0, grads['Wx'], grads['Wh'], grads['b'] = rnn_backward(dh, cache_rnn)\n",
    "    grads['W_embed'] = word_embedding_backward(dx, cache_embed)\n",
    "    grads['b_proj'] = np.sum(dh0, axis=0)\n",
    "    grads['W_proj'] = features.T.dot(dh0)\n",
    "    \n",
    "    return loss, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"After finding ht, we compute the scores by:\n",
    "score=Wvocabâˆ—ht\"\"\" \n",
    "def temporal_affine_forward(x, w, b):\n",
    "   N, T, D = x.shape\n",
    "   M = b.shape[0]\n",
    "   out = x.reshape(N * T, D).dot(w).reshape(N, T, M) + b\n",
    "   cache = x, w, b, out\n",
    "   return out, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_softmax_loss(x, y, mask):\n",
    "  N, T, V = x.shape\n",
    "  \n",
    "  x_flat = x.reshape(N * T, V)\n",
    "  y_flat = y.reshape(N * T)\n",
    "  mask_flat = mask.reshape(N * T)\n",
    "  \n",
    "  # We compute the softmax. We minus the score with a max for better numerical stability.\n",
    "  probs = np.exp(x_flat - np.max(x_flat, axis=1, keepdims=True))\n",
    "  probs /= np.sum(probs, axis=1, keepdims=True)\n",
    "  \n",
    "  # Compute the softmax loss: negative log likelihood aka cross entropy loss\n",
    "  loss = -np.sum(mask_flat * np.log(probs[np.arange(N * T), y_flat])) / N\n",
    "\n",
    "  # Compute the gradient\n",
    "  dx_flat = probs.copy()  \n",
    "  dx_flat[np.arange(N * T), y_flat] -= 1\n",
    "  dx_flat /= N\n",
    "  dx_flat *= mask_flat[:, None]\n",
    "  \n",
    "  dx = dx_flat.reshape(N, T, V)\n",
    "  \n",
    "  return loss, dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_step_forward(x, prev_h, Wx, Wh, b):\n",
    "  next_h, cache = None, None\n",
    "  state = np.dot(x, Wx) + np.dot(prev_h, Wh) + b\n",
    "  next_h = np.tanh(state)\n",
    "\n",
    "  cache = x, prev_h, Wx, Wh, state\n",
    "  return next_h, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_forward(x, h0, Wx, Wh, b):\n",
    "  \"\"\"\n",
    "    x: the true caption\n",
    "  \"\"\"\t\n",
    "  h, cache = None, None\n",
    "  N, T, D = x.shape\n",
    "  \n",
    "  # H is the dimension of the hidden state\n",
    "  H = h0.shape[1]\n",
    "\n",
    "  # h hold all the hidden states in all T steps\n",
    "  h = np.zeros((N, T, H))\n",
    "  \n",
    "  state = {}\n",
    "  state[-1] = h0\n",
    "  \n",
    "  cache_step = [None] * T\n",
    "\n",
    "  # Unroll T steps\n",
    "  for t in range(T):\n",
    "    # Get the true label at t\t  \n",
    "    xt = x[:, t, :]\n",
    "    # Compute one RNN step\n",
    "    state[t], cache_step[t] = rnn_step_forward(xt, state[t-1], Wx, Wh, b)\n",
    "    # Store the hidden state for time step t\n",
    "    h[:, t, :] = state[t]\n",
    "\n",
    "  cache = (cache_step, D)\n",
    "  return h, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h: (N, 16, hidden_dim)\n",
    "# Wx: (wordvec_dim, hidden_dim)\n",
    "# Wh: (hidden_dim, hidden_dim)\n",
    "h, cache_rnn = rnn_forward(x, h0, Wx, Wh, b)\n",
    "\n",
    "# W_vocal: (hidden_dim, vocab_size 1004)\n",
    "# scores: (N, 16, vocab_size 1004)\n",
    "scores, cache_scores = temporal_affine_forward(h, W_vocab, b_vocab)\n",
    "loss, dscores = temporal_softmax_loss(scores, captions_out, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, _ = affine_forward(next_h, W_vocab, b_vocab)\n",
    "captions[:, t] = scores.argmax(axis=1)\n",
    "prev_word = captions[:, t].reshape(N, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(self, features, max_length=30):\n",
    "    N = features.shape[0]\n",
    "    captions = self._null * np.ones((N, max_length), dtype=np.int32)\n",
    "\n",
    "    # Retrive all trainable parameters\n",
    "    W_proj, b_proj = self.params['W_proj'], self.params['b_proj']\n",
    "    W_embed = self.params['W_embed']\n",
    "    Wx, Wh, b = self.params['Wx'], self.params['Wh'], self.params['b']\n",
    "    W_vocab, b_vocab = self.params['W_vocab'], self.params['b_vocab']\n",
    "    \n",
    "    # N is the size of the data to test\n",
    "    # prev_word : (N, 1)\n",
    "    #\n",
    "    # next_h    : (N, hidden_dim)\n",
    "    # features  : (N, input_dim)\n",
    "    # W_proj    : (input_dim, hidden_dim)\n",
    "    #\n",
    "    # embed     : (N, 1, wordvec_dim)\n",
    "    # W-embed   : (vacab_size, wordvec_dim)\n",
    "    #\n",
    "    # next_c    : (N, hidden_dim*4) for LSTM\n",
    "    #\n",
    "    # scores    : (N, vocab_size)\n",
    "    # W_vocab     : (hidden_dim, vocab_size)\n",
    "    #\n",
    "    # captions  : (N, max_length)\n",
    "\n",
    "    # Set the first word as \"<start>\"\n",
    "    prev_word = self._start * np.ones((N, 1), dtype=np.int32)\n",
    "\n",
    "    # Compute h0\n",
    "    next_h, affine_cache = affine_forward(features, W_proj, b_proj)\n",
    "\n",
    "    H, _ = Wh.shape\n",
    "    # for each time step\n",
    "    for t in range(max_length):\n",
    "      # Compute the word vector.\n",
    "      embed, embed_cache = word_embedding_forward(prev_word, W_embed)\n",
    "      # Compute h from the RNN\n",
    "      next_h, cache = rnn_step_forward(np.squeeze(embed), next_h, Wx, Wh, b)\n",
    "      # Map h to scores for each vocabulary word\n",
    "      scores, _ = affine_forward(next_h, W_vocab, b_vocab)\n",
    "      # Set the caption word at time t.\n",
    "      captions[:, t] = scores.argmax(axis=1)\n",
    "      # Set it to be the next word input in next time step.\n",
    "      prev_word = captions[:, t].reshape(N, 1)\n",
    "\n",
    "    return captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10\n",
      "1 5\n",
      "2 20\n",
      "3 30\n",
      "4 24\n",
      "5 56\n",
      "6 96\n"
     ]
    }
   ],
   "source": [
    "l1 =[10,5,20,30,24,56,96]\n",
    "for i,j in enumerate(l1):\n",
    "    print(i,j)\n",
    "d={i:j for i,j in enumerate(l1)}\n",
    "d2 ={j:i for i,j in enumerate(l1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 10, 1: 5, 2: 20, 3: 30, 4: 24, 5: 56, 6: 96}\n"
     ]
    }
   ],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10: 0, 5: 1, 20: 2, 30: 3, 24: 4, 56: 5, 96: 6}\n"
     ]
    }
   ],
   "source": [
    "print(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
