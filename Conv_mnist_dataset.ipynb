{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "#import tf.keras as keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, x_valid) = x_train[5000:], x_train[:5000] \n",
    "(y_train, y_valid) = y_train[5000:], y_train[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c6a4240>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = 28, 28\n",
    "x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (55000, 28, 28, 1) y_train shape: (55000, 10)\n",
      "55000 train set\n",
      "5000 validation set\n",
      "10000 test set\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Print the number of training, validation, and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_valid.shape[0], 'validation set')\n",
    "print(x_test.shape[0], 'test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (55000, 28, 28, 1) y_train shape: (55000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 32)        8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               401664    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 412,778\n",
      "Trainable params: 412,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "# Take a look at the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-803b73bfa899>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcheckpointer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model.weights.best.hdf5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose = 1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='model.weights.best.hdf5', verbose = 1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 69s 1ms/step - loss: 3.1733 - acc: 0.6422 - val_loss: 0.4950 - val_acc: 0.8332\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.49503, saving model to model.weights.best.hdf5\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 11s 202us/step - loss: 0.5486 - acc: 0.7988 - val_loss: 0.3828 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.49503 to 0.38278, saving model to model.weights.best.hdf5\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 11s 204us/step - loss: 0.4674 - acc: 0.8279 - val_loss: 0.3363 - val_acc: 0.8804\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.38278 to 0.33627, saving model to model.weights.best.hdf5\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 11s 201us/step - loss: 0.4329 - acc: 0.8394 - val_loss: 0.3260 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.33627 to 0.32595, saving model to model.weights.best.hdf5\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 11s 198us/step - loss: 0.4047 - acc: 0.8507 - val_loss: 0.3131 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.32595 to 0.31314, saving model to model.weights.best.hdf5\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 11s 199us/step - loss: 0.3814 - acc: 0.8573 - val_loss: 0.3035 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.31314 to 0.30350, saving model to model.weights.best.hdf5\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 11s 197us/step - loss: 0.3664 - acc: 0.8640 - val_loss: 0.2781 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.30350 to 0.27809, saving model to model.weights.best.hdf5\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 11s 198us/step - loss: 0.3575 - acc: 0.8693 - val_loss: 0.2681 - val_acc: 0.9010\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.27809 to 0.26814, saving model to model.weights.best.hdf5\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 11s 198us/step - loss: 0.3450 - acc: 0.8736 - val_loss: 0.2673 - val_acc: 0.9038\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.26814 to 0.26733, saving model to model.weights.best.hdf5\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 11s 198us/step - loss: 0.3327 - acc: 0.8762 - val_loss: 0.2628 - val_acc: 0.9064\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.26733 to 0.26278, saving model to model.weights.best.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x143c29b0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test set\n",
    "score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 87us/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "score = model.evaluate(x_test,y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test accuracy: 0.8972\n"
     ]
    }
   ],
   "source": [
    "# Print test accuracy\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2851205890059471, 0.8972]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2 = model.predict(x_test,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 7, 7, 16)          4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 144)               576       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               37120     \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 100)               25700     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 89,158\n",
      "Trainable params: 88,358\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.Sequential()\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model2.add(keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', input_shape=(28,28,1))) \n",
    "model2.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model2.add(keras.layers.Dropout(0.3))\n",
    "model2.add(keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model2.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model2.add(keras.layers.Dropout(0.3))\n",
    "model2.add(keras.layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu'))\n",
    "model2.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model2.add(keras.layers.Dropout(0.3))\n",
    "model2.add(keras.layers.Flatten())\n",
    "model2.add(keras.layers.BatchNormalization())\n",
    "model2.add(keras.layers.Dense(256, activation='relu'))\n",
    "model2.add(keras.layers.Dropout(0.5))\n",
    "model2.add(keras.layers.BatchNormalization())\n",
    "model2.add(keras.layers.Dense(100, activation='relu'))\n",
    "model2.add(keras.layers.Dense(10, activation='softmax'))\n",
    "# Take a look at the model summary\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "55000/55000 [==============================] - 18s 320us/step - loss: 0.6711 - acc: 0.7779 - val_loss: 0.1007 - val_acc: 0.9682\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/3\n",
      "55000/55000 [==============================] - 16s 291us/step - loss: 0.2215 - acc: 0.9306 - val_loss: 0.0636 - val_acc: 0.9806\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/3\n",
      "55000/55000 [==============================] - 16s 292us/step - loss: 0.1601 - acc: 0.9494 - val_loss: 0.0518 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x5d3f98d0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=64,\n",
    "         epochs=3,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 108us/step\n"
     ]
    }
   ],
   "source": [
    "score = model2.evaluate(x_test,y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04589727868754417, 0.985]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
